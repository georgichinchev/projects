{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport sklearn\nfrom statsmodels.tsa.stattools import adfuller\nimport optuna\nimport scipy\nfrom scipy import stats\nfrom numpy import log\nfrom sklearn.model_selection import  train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Data importation and descriptive statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('../input/jane-street-market-prediction/train.csv',index_col = 'ts_id', squeeze = True)\ndata_validation = pd.read_csv('../input/jane-street-market-prediction/example_test.csv',index_col = 'ts_id', squeeze = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.Checking for missing values and imputing them with their mean (if any)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_validation.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There a lot of missing values. They will be imputed with their mean"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.fillna((data_train.mean()), inplace=True)\ndata_validation.fillna((data_validation.mean()), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking if all missing values are imputed"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_validation.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    3. Creating additional columns  the returns over different time periods. They will be used when\n    creating an action column - whether a certain trade to be done. \n    The condition is to have positive return - there will be no money loss\n    The output is binary:\n    1 - the trade shall be executed\n    0 - the trade will be missed\n    \n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train['ret1'] = data_train['weight']*data_train['resp']\ndata_train['ret2'] = data_train['weight']*data_train['resp_1']\ndata_train['ret3'] = data_train['weight']*data_train['resp_2']\ndata_train['ret4'] = data_train['weight']*data_train['resp_3']\ndata_train['ret5'] = data_train['weight']*data_train['resp_4']\ndata_train['action'] = np.where((data_train['ret1']>0)|(data_train['ret2']>0)|(data_train['ret3']>0)|(data_train['ret4']>0)|(data_train['ret5']>0),1,0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing ret columns as they are not needed anymore"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.drop(['ret1','ret2','ret3','ret4','ret5'], axis = 1, inplace =True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Checking the distribution of the data. A Jarque-Bera test is performed. A p-value will determine if the featuredata has a normal distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"for _, i in data_train.loc[:,data_train.columns.str.contains('feature')].items():\n  jb_test = stats.jarque_bera(i)\n  print(i.name, jb_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The p-value for all columns is 0 and the data has a normal distribution"},{"metadata":{},"cell_type":"markdown","source":"6. The dataset is huge, so a Bootstrapping will be used to get random sample\nI will start with 100000 from the features\n\nBootstrapping"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\nboot = resample(data_train, replace=True, n_samples=100000, random_state=42)\nprint('Bootstrap Sample: %s' % boot)\n# out of bag observations\noob = [x for x in data_train if x not in boot]\nprint('OOB Sample: %s' % oob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. Separating the train data set between feature values (A) and target value column B  "},{"metadata":{"trusted":true},"cell_type":"code","source":"A = boot.loc[:, boot.columns.str.contains('feature')]\nB = boot.loc[:,'action']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"6. MODEL","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%whos","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Separating a train and test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"A_train,A_test,B_train, B_test = train_test_split(A,B, test_size=0.3, random_state = 42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(A_train, label=B_train)\ndtest  = xgb.DMatrix(A_test, label=B_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%whos\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 400, 600),\n        'max_depth': trial.suggest_int('max_depth', 10, 20),\n        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, .1),\n        'subsample': trial.suggest_uniform('subsample', 0.50, 1),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n        'gamma': trial.suggest_int('gamma', 0, 10),\n        'tree_method' : 'gpu_hist',\n        'objective': 'binary:logistic'\n    }\n    \n    bst = xgb.train(params, dtrain)\n    preds = bst.predict(dtest)\n    pred_labels = np.rint(preds)\n    accuracy = sklearn.metrics.accuracy_score(B_test, pred_labels)\n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective,n_trials=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = optuna.visualization.plot_param_importances(study)\nfig.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = study.best_trial.params\nbest_params['tree_method'] = 'gpu_hist'\nbest_params['objective'] = 'binary:logistic'\nclf = xgb.XGBClassifier(**best_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(A, B)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"%whos","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npreds =clf.predict(A_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(preds)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}