{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import optuna\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from numpy import log\n",
    "from sklearn.model_selection import  train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data importation and descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../input/jane-street-market-prediction/train.csv',index_col = 'ts_id', squeeze = True)\n",
    "data_validation = pd.read_csv('../input/jane-street-market-prediction/example_test.csv',index_col = 'ts_id', squeeze = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Checking for missing values and imputing them with their mean (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There a lot of missing values. They will be imputed with their mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.fillna((data_train.mean()), inplace=True)\n",
    "data_validation.fillna((data_validation.mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if all missing values are imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Creating additional columns  the returns over different time periods. They will be used when\n",
    "    creating an action column - whether a certain trade to be done. \n",
    "    The condition is to have positive return - there will be no money loss\n",
    "    The output is binary:\n",
    "    1 - the trade shall be executed\n",
    "    0 - the trade will be missed\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['ret1'] = data_train['weight']*data_train['resp']\n",
    "data_train['ret2'] = data_train['weight']*data_train['resp_1']\n",
    "data_train['ret3'] = data_train['weight']*data_train['resp_2']\n",
    "data_train['ret4'] = data_train['weight']*data_train['resp_3']\n",
    "data_train['ret5'] = data_train['weight']*data_train['resp_4']\n",
    "data_train['action'] = np.where((data_train['ret1']>0)|(data_train['ret2']>0)|(data_train['ret3']>0)|(data_train['ret4']>0)|(data_train['ret5']>0),1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing ret columns as they are not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(['ret1','ret2','ret3','ret4','ret5'], axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Checking the distribution of the data. A Jarque-Bera test is performed. A p-value will determine if the featuredata has a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, i in data_train.loc[:,data_train.columns.str.contains('feature')].items():\n",
    "  jb_test = stats.jarque_bera(i)\n",
    "  print(i.name, jb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value for all columns is 0 and the data has a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. The dataset is huge, so a Bootstrapping will be used to get random sample\n",
    "I will start with 100000 from the features\n",
    "\n",
    "Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "boot = resample(data_train, replace=True, n_samples=100000, random_state=42)\n",
    "print('Bootstrap Sample: %s' % boot)\n",
    "# out of bag observations\n",
    "oob = [x for x in data_train if x not in boot]\n",
    "print('OOB Sample: %s' % oob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Separating the train data set between feature values (A) and target value column B  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = boot.loc[:, boot.columns.str.contains('feature')]\n",
    "B = boot.loc[:,'action']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating a train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train,A_test,B_train, B_test = train_test_split(A,B, test_size=0.3, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(A_train, label=B_train)\n",
    "dtest  = xgb.DMatrix(A_test, label=B_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 400, 600),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 20),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, .1),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.50, 1),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n",
    "        'gamma': trial.suggest_int('gamma', 0, 10),\n",
    "        'tree_method' : 'gpu_hist',\n",
    "        'objective': 'binary:logistic'\n",
    "    }\n",
    "    \n",
    "    bst = xgb.train(params, dtrain)\n",
    "    preds = bst.predict(dtest)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(B_test, pred_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective,n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_param_importances(study)\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "best_params['tree_method'] = 'gpu_hist'\n",
    "best_params['objective'] = 'binary:logistic'\n",
    "clf = xgb.XGBClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds =clf.predict(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
